{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap14-2. 순환 신경망 (RNN, Recurrent Neural Network) - (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저번 포스팅인 [07-1. 순환 신경망 - (1)](http://excelsior-cjh.tistory.com/183)에서는 시계열 데이터에 적합한 모델인 RNN의 구조와 텐서플로(TensorFlow)의 `BasicRNNCell`과 `static_rnn()`, `dynamic_rnn()`을 이용해 RNN을 구현하는 방법에 대해 알아보았다. 이번 포스팅에서는 RNN을 학습시키는 방법과 심층 RNN에 대해 알아보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RNN 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 BPTT (BackPropagation Through Time)\n",
    "\n",
    "RNN은 기존 신경망의 역전파(backprop)와는 달리 타임 스텝별로 네트워크를 펼친 다음, 역전파 알고리즘을 사용하는데 이를 **BPTT**(BackPropagation Through Time)라고 한다. \n",
    "\n",
    "![BPTT](./images/bptt01.png)\n",
    "\n",
    "BPTT 또한 일반적인 역전파와 같이 먼저 순전파(forward prop)로 각 타임 스텝별 시퀀스를 출력한다. 그런다음 이 출력 시퀀스와 손실(비용)함수를 사용하여 각 타임 스텝별 Loss를 구한다. 그리고 손실 함수의 그래디언트는 위의 그림과 같이 펼쳐진 네트워크를 따라 역방향으로 전파된다. BPTT는 그래디언트가 마지막 타임 스텝인 출력뿐만 아니라 손실함수를 사용한 모든 출력에서 역방향으로 전파된다.  \n",
    "\n",
    "RNN은 각 타임 스텝마다 같은 매개변수 $\\mathbf{W}$ 와 $\\mathbf{b}$ 이 사용되기 때문에 역전파가 진행되면서 모든 타임 스텝에 걸쳐 매개변수 값이 합산된다. 이렇게 업데이트된 가중치는 순전파 동안에는 모든 타임 스텝에 동일한 가중치가 적용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Truncated BPTT\n",
    "\n",
    "3.1에서 살펴본 BPTT는 전체의 타임 스텝마다 처음부터 끝까지 역전파를 하기 때문에 타임 스텝이 클 수록 계산량이 많아지는 문제가 있다. 이러한 계산량 문제를 해결하기 위해 전체 타임 스텝을 일정 구간(예를들어 3 또는 5 구간)으로 나눠 역전파를 하는 **Truncated BPTT**를 사용한다. \n",
    "\n",
    "\n",
    "\n",
    "![truncated-bptt](./images/bptt02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 RNN을 이용한 분류기 구현\n",
    "\n",
    " 이번에는 RNN을 이용해 MNIST 숫자 이미지 데이터셋을 분류하는 분류기를 구현해보자. MNIST와 같은 이미지 데이터는 이전 포스팅 [06. 합성곱 신경망](http://excelsior-cjh.tistory.com/180)에서 살펴본 이미지의 공간(spatial) 구조를 활용하는 CNN 모델이 더 적합하지만, 인접한 영역의 픽셀은 서로 연관되어 있으므로 이를 시퀀스 데이터로 볼 수도 있다.   아래의 그림처럼 MNIST 데이터에서 `28 x 28` 픽셀을 시퀀스의 각원소는 `28`개의 픽셀을 가진 길이가 `28` 시퀀스 데이터로 볼 수 있다.\n",
    "\n",
    "![](./images/mnist_seq.png)\n",
    "\n",
    "\n",
    "\n",
    "아래의 코드는 텐서플로(TensorFlow)의 `BasicRNNCell`과 `dynamic_rnn()`을 이용해 MNIST 분류기를 구현한 코드이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "# matplotlib.rc('font', family='AppleGothic')  # MacOS\n",
    "matplotlib.rc('font', family='Malgun Gothic')  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape : (55000, 784)\n",
      "valid_x.shape : (5000, 28, 28)\n",
      "test_x.shape : (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "train_x = train_x.astype(np.float32).reshape(-1, 28*28) / 255.0  # (784,)\n",
    "test_x = test_x.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)\n",
    "valid_x, train_x = train_x[:5000], train_x[5000:]\n",
    "valid_y, train_y = train_y[:5000], train_y[5000:]\n",
    "test_x = test_x.reshape([-1, n_steps, n_inputs])\n",
    "valid_x = valid_x.reshape([-1, n_steps, n_inputs])\n",
    "\n",
    "print('train_x.shape :', train_x.shape)\n",
    "print('valid_x.shape :', valid_x.shape)\n",
    "print('test_x.shape :', test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-batch\n",
    "def shuffle_batch(features, labels, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(features))\n",
    "    n_batches = len(features) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        batch_x, batch_y = features[batch_idx], labels[batch_idx]\n",
    "        yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "################\n",
    "# Layer Params #\n",
    "################\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "labels = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# RNN Model\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, inputs, dtype=tf.float32)\n",
    "# dense layer\n",
    "logits = tf.layers.dense(states, n_outputs)  # states = outputs[-1]\n",
    "\n",
    "# loss\n",
    "xentropy = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "\n",
    "################\n",
    "# Train Params #\n",
    "################\n",
    "learning_rate = 0.001\n",
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "# optimizer\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(xentropy)\n",
    "\n",
    "# metric\n",
    "correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 000 acc_batch : 0.9533, acc_valid : 0.9322 loss_batch : 0.1928\n",
      "epoch : 001 acc_batch : 0.9600, acc_valid : 0.9530 loss_batch : 0.1873\n",
      "epoch : 002 acc_batch : 0.9600, acc_valid : 0.9520 loss_batch : 0.2149\n",
      "epoch : 003 acc_batch : 0.9600, acc_valid : 0.9606 loss_batch : 0.1332\n",
      "epoch : 004 acc_batch : 0.9800, acc_valid : 0.9730 loss_batch : 0.0784\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_x, batch_y in shuffle_batch(train_x, train_y, batch_size):\n",
    "            batch_x = batch_x.reshape([-1, n_steps, n_inputs])\n",
    "            sess.run(train_op, \n",
    "                     feed_dict={inputs: batch_x, labels: batch_y})\n",
    "        acc_batch = accuracy.eval(feed_dict={inputs: batch_x, labels: batch_y})\n",
    "        acc_valid = accuracy.eval(feed_dict={inputs: valid_x, labels: valid_y})\n",
    "        loss_batch = xentropy.eval(feed_dict={inputs: batch_x, labels: batch_y})\n",
    "        print('epoch : {:03d}'.format(epoch),\n",
    "              'acc_batch : {:.4f}, acc_valid : {:.4f}'.format(acc_batch, acc_valid),\n",
    "              'loss_batch : {:.4f}'.format(loss_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
